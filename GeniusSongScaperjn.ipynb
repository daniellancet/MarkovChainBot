{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "access_token = open(\"/Users/daniellancet/Desktop/Projects/Markov_Chain_Beginner_Project/API_Key.txt\").readline() \n",
    "\n",
    "# Base URL and headers for Genius API\n",
    "base_url = 'https://api.genius.com'\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_song_ids(artist_name, max_results=10):\n",
    "    search_url = f'{base_url}/search'\n",
    "    params = {'q': artist_name, 'page': 1, 'per_page': max_results}\n",
    "    \n",
    "    song_ids = []\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        params['page'] = page\n",
    "        response = requests.get(search_url, headers=headers, params=params).json()\n",
    "        hits = response['response']['hits']\n",
    "        \n",
    "        if not hits:\n",
    "            break\n",
    "        \n",
    "        for hit in hits:\n",
    "            song_id = hit['result']['id']\n",
    "            song_ids.append(song_id)\n",
    "        \n",
    "        if len(hits) < max_results:\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "    \n",
    "    return song_ids\n",
    "\n",
    "def get_song_urls(song_ids):\n",
    "    song_urls = []\n",
    "    for song_id in song_ids:\n",
    "        song_url = f'{base_url}/songs/{song_id}'\n",
    "        response = requests.get(song_url, headers=headers).json()\n",
    "        lyrics_path = response['response']['song']['path']\n",
    "        lyrics_url = f'https://genius.com{lyrics_path}'\n",
    "        song_urls.append(lyrics_url)\n",
    "    return song_urls\n",
    "\n",
    "    \n",
    "def get_song_lyrics(song_url):\n",
    "    response = requests.get(song_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Failed to fetch lyrics page: {response.status_code}\"\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the div with data-lyrics-container attribute\n",
    "    lyrics_divs = soup.find_all('div', attrs={'data-lyrics-container': 'true'})\n",
    "    \n",
    "    if not lyrics_divs:\n",
    "        return \"Lyrics not found on the page.\"\n",
    "    \n",
    "    # Combine the text from all such divs (there might be multiple)\n",
    "    lyrics = \"\\n\".join([div.get_text(separator=\"\\n\", strip=True) for div in lyrics_divs])\n",
    "    lyrics  = lyrics.replace('\\n', ' ')\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '  ', lyrics)\n",
    "    \n",
    "    return lyrics\n",
    "\n",
    "\n",
    "def get_song_lyrics_txt(song_url, output_file):\n",
    "    response = requests.get(song_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Failed to fetch lyrics page: {response.status_code}\"\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "\n",
    "    lyrics_divs = soup.find_all('div', attrs={'data-lyrics-container': 'true'})\n",
    "    \n",
    "    if not lyrics_divs:\n",
    "        return \"Lyrics not found on the page.\"\n",
    "    \n",
    "    \n",
    "    lyrics = \"\\n\".join([div.get_text(separator=\"\\n\", strip=True) for div in lyrics_divs])\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '  ', lyrics)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(lyrics)\n",
    "    \n",
    "    return f\"Lyrics successfully written to {output_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_url = \"https://genius.com/Ed-sheeran-thinking-out-loud-lyrics\"\n",
    "sample_lyrics = get_song_lyrics_txt(sample_url, \"Song-Lyrics/thinking_out_loud.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_songs(artist_name, max_res=10):\n",
    "    song_ids = get_song_ids(artist_name, max_res)\n",
    "    song_urls = get_song_urls(song_ids)\n",
    "    artist_name = artist_name.replace(\" \", \"-\")\n",
    "    for id, url in zip(song_ids, song_urls):\n",
    "        \n",
    "        path = f\"Song-Lyrics/{artist_name}/{str(id)}.txt\"\n",
    "        get_song_lyrics_txt(url, path)\n",
    "\n",
    "\n",
    "#get_artist_songs(\"Kendrick Lamar\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
